{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa0eb1e-ee95-48f4-9de2-980534cc022d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np \n",
    "\n",
    "# ##############################################################################\n",
    "# SEGMENTATION CLASS\n",
    "# ##############################################################################\n",
    "class SegmenterNet(object):\n",
    "    def __init__(self, cfg, model_ckp_name=\"\"):\n",
    "        \"\"\" Initializes a Segmentation Model Class \"\"\"\n",
    "\n",
    "        # MODEL SETTINGS\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if model_ckp_name != \"\":\n",
    "            self.checkpoint_file = model_ckp_name\n",
    "            self.log_dir =  self.cfg.log_path + \"inference_results\"\n",
    "            if not os.path.exists(self.log_dir):\n",
    "                os.makedirs(self.log_dir)\n",
    "        else:\n",
    "            # DIRECTORIES TO STORE OUTPUTS\n",
    "            if not self.cfg.log_name ==\"\":\n",
    "                self.log_dir = self.cfg.log_path + \"{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\")) + \"_\" + self.cfg.log_name\n",
    "            else:\n",
    "                self.log_dir = self.cfg.log_path + \"{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "            if not os.path.exists(self.log_dir):\n",
    "                os.makedirs(self.log_dir)\n",
    "                self.checkpoint_file = os.path.join(self.log_dir , \"model.chk\")\n",
    "            else:\n",
    "                self.checkpoint_file = os.path.join(self.log_dir , \"model.chk\")\n",
    "\n",
    "        # Create log file\n",
    "        log_filename = os.path.join(self.log_dir, \"net_parameters.txt\")\n",
    "        self.log_file = open(log_filename, 'w+')\n",
    "\n",
    "        self.init_network_model()\n",
    "\n",
    "    def init_network_model(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.create_input_ops()\n",
    "\n",
    "            self.logits = create_SalsaNet(self.input_img, self.cfg.NUM_CLASS,dropout_rate=self.cfg.DROPOUT_PROB, is_training=self.is_training)\n",
    "\n",
    "            self.store_network_parameters()\n",
    "\n",
    "            with tf.compat.v1.name_scope(\"preds\") as scope:\n",
    "                self.preds = tf.cast(tf.argmax(input=self.logits, axis=-1), name=scope, dtype=tf.int32)\n",
    "\n",
    "            self.create_loss_ops()\n",
    "            self.create_optimization_ops()\n",
    "            self.create_evaluation_metric_ops()\n",
    "            self.create_summary_ops()\n",
    "\n",
    "    def create_input_ops(self):\n",
    "        with tf.compat.v1.variable_scope(\"parameters\"):\n",
    "            input_img_shape = (None, self.cfg.IMAGE_HEIGHT, self.cfg.IMAGE_WIDTH, self.cfg.IMAGE_CHANNEL)\n",
    "            output_img_shape = (None, self.cfg.IMAGE_HEIGHT, self.cfg.IMAGE_WIDTH)\n",
    "            self.input_img = tf.compat.v1.placeholder(tf.float32, shape=input_img_shape, name=\"input_img\")\n",
    "            self.output_img = tf.compat.v1.placeholder(tf.int32, shape=output_img_shape, name=\"output_img\")\n",
    "            self.weight_img = tf.compat.v1.placeholder(tf.float32, shape=output_img_shape, name=\"weight_img\")\n",
    "            self.dropout = tf.compat.v1.placeholder_with_default(self.cfg.DROPOUT_PROB, shape=None, name=\"dropout\")\n",
    "            self.is_training = tf.compat.v1.placeholder_with_default(False, shape=(), name=\"is_training\")\n",
    "\n",
    "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            self.learning_rate = tf.compat.v1.train.exponential_decay(learning_rate=self.cfg.LEARNING_RATE,\n",
    "                                            global_step=self.global_step,\n",
    "                                            decay_steps=self.cfg.LR_DECAY_CYCLE,\n",
    "                                            decay_rate=self.cfg.LR_DECAY_FACTOR,\n",
    "                                            staircase=True,\n",
    "                                            name=\"learningrate\")\n",
    "\n",
    "            # Create a summary to monitor the learning rate\n",
    "            tf.compat.v1.summary.scalar(\"learning_rate\", self.learning_rate)\n",
    "\n",
    "    def store_network_parameters(self):\n",
    "\n",
    "        self.log_file.write(\"\\n\" +  (\"#\" * 70) + \"\\n\" + (\"#\" * 29)  + \" parameters \" + (\"#\" * 29) + \"\\n\" + (\"#\" * 70) + \"\\n\")\n",
    "\n",
    "        for k, v in sorted(self.cfg.items()):\n",
    "            text_to_write = str(k) + \" : \" + str(v) + \"\\n\"\n",
    "            self.log_file.write(text_to_write)\n",
    "\n",
    "        self.log_file.write(\"\\n\" +  (\"#\" * 70) +  \"\\n\" + (\"#\" * 70) + \"\\n\")\n",
    "        self.log_file.close()\n",
    "\n",
    "    def create_loss_ops(self):\n",
    "        # LOSS FUNCTION\n",
    "        with tf.compat.v1.variable_scope('loss') as scope:\n",
    "            unrolled_logits = tf.reshape(self.logits, (-1, self.cfg.NUM_CLASS))\n",
    "            unrolled_labels = tf.reshape(self.output_img, (-1,))\n",
    "            unrolled_weights = tf.reshape(self.weight_img, (-1,))\n",
    "            cross_entropy = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=unrolled_labels, logits=unrolled_logits, weights=unrolled_weights)\n",
    "            self.loss  = tf.reduce_mean(input_tensor=cross_entropy)\n",
    "\n",
    "            # Create a summary to monitor the loss\n",
    "            tf.compat.v1.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "    def create_optimization_ops(self):\n",
    "        # OPTIMIZATION METHOD\n",
    "        with tf.compat.v1.variable_scope('opt') as scope:\n",
    "            self.optimizer = tf.compat.v1.train.AdamOptimizer(self.learning_rate, name=\"optimizer\")\n",
    "            update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step, name=\"train_op\")\n",
    "\n",
    "    def create_evaluation_metric_ops(self):\n",
    "        # EVALUATION METRIC - Intersection over Union IoU\n",
    "        with tf.compat.v1.name_scope(\"evaluation\") as scope:\n",
    "            # Define the evaluation metric and update operations\n",
    "            self.evaluation, self.update_evaluation_vars = tf.compat.v1.metrics.mean_iou(\n",
    "                tf.reshape(self.output_img, [-1]),\n",
    "                tf.reshape(self.preds, [-1]),\n",
    "                num_classes=self.cfg.NUM_CLASS,\n",
    "                name=scope)\n",
    "            # Isolate metric's running variables & create their initializer and reset operators\n",
    "            evaluation_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.LOCAL_VARIABLES, scope=scope)\n",
    "            self.reset_evaluation_vars = tf.compat.v1.variables_initializer(var_list=evaluation_vars)\n",
    "\n",
    "    def create_summary_ops(self):\n",
    "        with tf.compat.v1.name_scope('summary'):\n",
    "            self.summary_writer = tf.compat.v1.summary.FileWriter(self.log_dir, graph=self.graph)\n",
    "            self.saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables(),name=\"saver\", max_to_keep=1)\n",
    "            self.summary_op = tf.compat.v1.summary.merge_all()\n",
    "\n",
    "    def train_segmenter(self, training_data_path, validation_data_path):\n",
    "\n",
    "        with tf.compat.v1.Session(graph=self.graph) as sess:\n",
    "            self.initialize_vars(sess)\n",
    "\n",
    "            for epoch in range(1, self.cfg.NUM_EPOCHS+1):\n",
    "                timeStart = time.time()\n",
    "\n",
    "                # generate batches\n",
    "                training_batches, n_training_samples = generate_lidar_batch_function(training_data_path, channel_nbr=self.cfg.IMAGE_CHANNEL, class_nbr= self.cfg.NUM_CLASS, loss_weights=self.cfg.CLS_LOSS_WEIGHTS, augmentation=self.cfg.DATA_AUGMENTATION)\n",
    "                validation_batches, n_validation_samples = generate_lidar_batch_function(validation_data_path, channel_nbr=self.cfg.IMAGE_CHANNEL, class_nbr= self.cfg.NUM_CLASS, loss_weights=self.cfg.CLS_LOSS_WEIGHTS, augmentation=self.cfg.DATA_AUGMENTATION)\n",
    "\n",
    "                # Num batches per epoch\n",
    "                n_batches = int(np.ceil(n_training_samples / self.cfg.BATCH_SIZE))\n",
    "\n",
    "                # Iterate through each mini-batch\n",
    "                for step in range(n_batches):\n",
    "\n",
    "                    # get next batch data\n",
    "                    X_batch, Y_batch, W_batch = next(training_batches(self.cfg.BATCH_SIZE))\n",
    "\n",
    "                    if self.cfg.DEBUG_MODE:\n",
    "                        print('X_batch', X_batch.shape, X_batch.dtype, X_batch.min(), X_batch.max())\n",
    "                        print('Y_batch', Y_batch.shape, Y_batch.dtype, Y_batch.min(), Y_batch.max())\n",
    "                        print('W_batch', W_batch.shape, W_batch.dtype, W_batch.min(), W_batch.max()) \n",
    "\n",
    "                    # Runtime metadata\n",
    "                    run_options = tf.compat.v1.RunOptions(trace_level=tf.compat.v1.RunOptions.FULL_TRACE)\n",
    "                    run_metadata = tf.compat.v1.RunMetadata()\n",
    "\n",
    "                    # Train\n",
    "                    feed_dict = {self.input_img:X_batch, self.output_img:Y_batch, self.weight_img:W_batch, self.is_training:True}\n",
    "                    loss, _, summary = sess.run([self.loss, self.train_op, self.summary_op], feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n",
    "\n",
    "                    tag_name= 'epoch {} step {}'.format(epoch, step)\n",
    "                    self.summary_writer.add_summary(summary, n_batches*(epoch-1)+step)\n",
    "\n",
    "                    # force tensorflow to synchronise summaries\n",
    "                    self.summary_writer.flush()\n",
    "\n",
    "                    # Print feedback every so often\n",
    "                    if self.cfg.PRINT_EVERY != None and (step+1)%self.cfg.PRINT_EVERY==0:\n",
    "                        timeElapsed = time.time() - timeStart\n",
    "                        print(\" EPOCH {}/{} step: {: 5d} Batch loss: {:3.5f} Time avg: {:3.5f} sec\".format(epoch, self.cfg.NUM_EPOCHS, step+1, loss, timeElapsed/self.cfg.PRINT_EVERY))\n",
    "                        timeStart = time.time()\n",
    "\n",
    "                # Evaluate on train and validation sets after each epoch\n",
    "                train_iou, train_loss, train_ious, train_precs, train_recalls = self.evaluate(training_batches, n_training_samples, sess)\n",
    "                valid_iou, valid_loss, valid_ious, valid_precs, valid_recalls = self.evaluate(validation_batches, n_validation_samples, sess)\n",
    "\n",
    "                # print scores\n",
    "                self.print_evaluation_scores(train_iou, train_loss, train_ious, train_precs, train_recalls, tag=\"Training\")\n",
    "                self.print_evaluation_scores(valid_iou, valid_loss, valid_ious, valid_precs, valid_recalls, tag=\"Validation\")\n",
    "\n",
    "                # keep summary data after each epoch\n",
    "                self.save_summaries(sess, train_loss, train_iou, valid_loss, valid_iou, train_ious, train_precs, train_recalls, valid_ious, valid_precs, valid_recalls, epoch)\n",
    "\n",
    "    def initialize_vars(self, session):\n",
    "        if tf.compat.v1.train.checkpoint_exists(self.checkpoint_file):\n",
    "            print(\"- Restoring parameters from saved checkpoints\")\n",
    "            print(\"  -\", self.checkpoint_file)\n",
    "            self.saver.restore(session, self.checkpoint_file)\n",
    "        else:\n",
    "            print(\"Initializing weights to random values\")\n",
    "            session.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    def predict(self, batch_data, session):\n",
    "        # MAKE PREDICTIONS ON SINGLE BATCH DATA\n",
    "        feed_dict = {self.input_img:batch_data, self.is_training:False}\n",
    "        batch_preds = session.run(self.preds, feed_dict=feed_dict)\n",
    "        preds = batch_preds.squeeze()\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def predict_single_image(self, input_img, session):\n",
    "        # MAKE PREDICTIONS ON SINGLE IMAGE DATA\n",
    "\n",
    "        # expand image dimension\n",
    "        temp_img = np.zeros((1, input_img.shape[0], input_img.shape[1], input_img.shape[2]))\n",
    "        temp_img[0, :, :, :] = input_img\n",
    "\n",
    "        # MAKE PREDICTIONS ON SINGLE IMAGE\n",
    "        feed_dict = {self.input_img: temp_img, self.is_training: False}\n",
    "        timeStart = time.time()\n",
    "        pred_img = session.run(self.preds, feed_dict=feed_dict)\n",
    "        timeElapsed = (time.time() - timeStart)*1000.0\n",
    "        print(\"predict_single_image took : {:3.5f} msec\".format(timeElapsed))\n",
    "\n",
    "        return pred_img[0]\n",
    "\n",
    "    def evaluate(self, batch_data, data_size, session):\n",
    "        # EVALUATE ON BATCH DATA\n",
    "        total_loss = 0\n",
    "        tps = []\n",
    "        fps = []\n",
    "        fns = []\n",
    "        n_samples = data_size\n",
    "        n_batches = int(np.ceil(n_samples/self.cfg.BATCH_SIZE)) # Num batches needed\n",
    "\n",
    "        # Reset the running variables for evaluation metric\n",
    "        session.run(self.reset_evaluation_vars)\n",
    "\n",
    "        # Iterate through each mini-batch\n",
    "        for step in range(n_batches):\n",
    "            # get next batch data\n",
    "            X_batch, Y_batch, W_batch = next(batch_data(self.cfg.BATCH_SIZE))\n",
    "            feed_dict = {self.input_img:X_batch, self.output_img:Y_batch, self.weight_img:W_batch, self.is_training:False}\n",
    "\n",
    "            # Get loss, and update running variables for evaluation metric\n",
    "            loss, preds, confusion_mtx = session.run([self.loss, self.preds, self.update_evaluation_vars], feed_dict=feed_dict)\n",
    "            total_loss += loss\n",
    "\n",
    "            #iou computation\n",
    "            tp, fp, fn = self.evaluate_iou(Y_batch, preds, self.cfg.NUM_CLASS)\n",
    "            tps.append(tp)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "\n",
    "\n",
    "        tps = np.array(tps)\n",
    "        fps = np.array(fps)\n",
    "        fns = np.array(fns)\n",
    "        epsilon = 1e-12\n",
    "        ious = tps.astype(float) / (tps + fns + fps + epsilon)\n",
    "        precision = tps.astype(float) / (tps + fps + epsilon)\n",
    "        recall = tps.astype(float) / (tps + fns + epsilon)\n",
    "\n",
    "        mean_ious = np.mean(ious, axis=0)\n",
    "        mean_prec = np.mean(precision, axis=0)\n",
    "        mean_recall = np.mean(recall, axis=0)\n",
    "\n",
    "        # Get the updated score from the running metric\n",
    "        score = session.run(self.evaluation)\n",
    "        # Average the loss\n",
    "        avg_loss = total_loss/float(n_batches)\n",
    "\n",
    "        return score, avg_loss, mean_ious, mean_prec, mean_recall\n",
    "\n",
    "    def evaluate_iou(self, label, pred, n_class):\n",
    "\n",
    "        assert label.shape == pred.shape, \\\n",
    "            'label and pred shape mismatch: {} vs {}'.format(\n",
    "                label.shape, pred.shape)\n",
    "\n",
    "        tps = np.zeros(n_class)\n",
    "        fns = np.zeros(n_class)\n",
    "        fps = np.zeros(n_class)\n",
    "\n",
    "        for cls_id in range(n_class):\n",
    "            tp = np.sum(pred[label == cls_id] == cls_id)\n",
    "            fp = np.sum(label[pred == cls_id] != cls_id)\n",
    "            fn = np.sum(pred[label == cls_id] != cls_id)\n",
    "\n",
    "            tps[cls_id] = tp\n",
    "            fps[cls_id] = fp\n",
    "            fns[cls_id] = fn\n",
    "\n",
    "        return tps, fps, fns\n",
    "\n",
    "    def expand_image_dimension(self, input_img):\n",
    "        # return pred results as colored rgb images\n",
    "        n_samples = input_img.shape[0]\n",
    "        output_img = np.zeros((n_samples, input_img.shape[1], input_img.shape[2], 3))\n",
    "        for i in range(0,n_samples):\n",
    "            label_map = input_img[i,:,:]\n",
    "            color_img = np.zeros((input_img.shape[1], input_img.shape[2], 3))\n",
    "            for j in range(0,self.cfg.NUM_CLASS):\n",
    "                color_img[label_map==j,:] = self.cfg.CLS_COLOR_MAP[j]\n",
    "\n",
    "            output_img[i,:,:,:] =color_img\n",
    "\n",
    "        return output_img\n",
    "\n",
    "    def save_summaries(self, sess, train_loss, train_iou, valid_loss, valid_iou, train_mean_ious, train_precs, train_recalls, valid_mean_ious, valid_precs, valid_recalls, epoch):\n",
    "\n",
    "        # Save checkpoints\n",
    "        self.saver.save(sess, self.checkpoint_file, global_step=epoch, write_meta_graph=True)\n",
    "\n",
    "        # Save training and validation summaries\n",
    "        summary = tf.compat.v1.Summary()\n",
    "        summary.value.add(tag='Training/Training Loss', simple_value=float(train_loss))\n",
    "        summary.value.add(tag='Validation/Validation Loss', simple_value=float(valid_loss))\n",
    "        summary.value.add(tag='Training/Training IOU', simple_value=float(train_iou))\n",
    "        summary.value.add(tag='Validation/Validation IOU', simple_value=float(valid_iou))\n",
    "\n",
    "\n",
    "        for i in range(0,self.cfg.NUM_CLASS):\n",
    "            tag_name = 'Training/' + self.cfg.CLASSES[i] + '/IOU'\n",
    "            summary.value.add(tag=tag_name, simple_value=float(train_mean_ious[i]))\n",
    "            tag_name = 'Training/' + self.cfg.CLASSES[i] + '/Prec'\n",
    "            summary.value.add(tag=tag_name, simple_value=float(train_precs[i]))\n",
    "            tag_name = 'Training/' + self.cfg.CLASSES[i] + '/Recall'\n",
    "            summary.value.add(tag=tag_name, simple_value=float(train_recalls[i]))\n",
    "\n",
    "            tag_name = 'Validation/' + self.cfg.CLASSES[i] + '/IOU'\n",
    "            summary.value.add(tag=tag_name, simple_value=float(valid_mean_ious[i]))\n",
    "            tag_name = 'Validation/' + self.cfg.CLASSES[i] + '/Prec'\n",
    "            summary.value.add(tag=tag_name, simple_value=float(valid_precs[i]))\n",
    "            tag_name = 'Validation/' + self.cfg.CLASSES[i] + '/Recall'\n",
    "            summary.value.add(tag=tag_name, simple_value=float(valid_recalls[i]))\n",
    "\n",
    "\n",
    "        self.summary_writer.add_summary(summary, epoch)\n",
    "\n",
    "        # force tensorflow to synchronise summaries\n",
    "        self.summary_writer.flush()\n",
    "\n",
    "    def print_evaluation_scores(self, iou, loss, ious, precs, recalls, tag=\"Training\"):\n",
    "\n",
    "        if tag==\"Training\":\n",
    "            s = \"TR IOU: {: 3.3f} TR IOU: {: 3.3f} TR LOSS: {: 3.5f} \"\n",
    "        else:\n",
    "            s = \"VR IOU: {: 3.3f} VR IOU: {: 3.3f} VR LOSS: {: 3.5f} \"\n",
    "        print(s.format(iou, np.mean(ious), loss))\n",
    "\n",
    "        for i in range(0,self.cfg.NUM_CLASS):\n",
    "            s = self.cfg.CLASSES[i] + \" PREC: {: 3.3f} \" + self.cfg.CLASSES[i] + \" REC: {: 3.3f} \" + self.cfg.CLASSES[i] + \" IOU: {: 3.3f}\"\n",
    "            print(s.format(precs[i], recalls[i], ious[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cd218-2694-4e9c-9ec8-de92122b99c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
