{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3e348d-e35d-4990-b5ff-ad575663019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n",
      "creating network model using gpu 0\n",
      "importing Jupyter notebook from segmenter.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from model.ipynb\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6\n",
      "no error\n",
      "{'BATCH_SIZE': 1,\n",
      " 'CHANNEL_LABELS': ['mean', 'max', 'ref', 'den'],\n",
      " 'CLASSES': ['background', 'road', 'vehicle'],\n",
      " 'CLS_2_ID': {'background': 0, 'road': 1, 'vehicle': 2},\n",
      " 'CLS_COLOR_MAP': array([[255., 255., 255.],\n",
      "       [  0., 255.,   0.],\n",
      "       [255.,   0.,   0.]]),\n",
      " 'CLS_LOSS_WEIGHTS': array([ 1.01,  6.03, 15.78]),\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': False,\n",
      " 'DROPOUT_PROB': 0.7,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 4,\n",
      " 'IMAGE_HEIGHT': 64,\n",
      " 'IMAGE_WIDTH': 256,\n",
      " 'LEARNING_RATE': 0.01,\n",
      " 'LR_DECAY_CYCLE': 20000,\n",
      " 'LR_DECAY_FACTOR': 0.1,\n",
      " 'NUM_CLASS': 3,\n",
      " 'NUM_EPOCHS': 2,\n",
      " 'PRINT_EVERY': 20,\n",
      " 'log_name': '',\n",
      " 'log_path': 'D:/salsaNet_bev/log',\n",
      " 'training_data_path': 'D:/salsaNet_bev/salsaNet_bev/salsaNet_bev_train',\n",
      " 'validation_data_path': 'D:/salsaNet_bev/salsaNet_bev/salsaNet_bev_val'}\n",
      "--------------- SalsaNet model --------------------\n",
      "input (None, 64, 256, 4)\n",
      "WARNING:tensorflow:From C:\\Users\\mahdi\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:562: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "logits (None, 64, 256, 3)\n",
      "WARNING:tensorflow:From <string>:188: checkpoint_exists (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "Initializing weights to random values\n",
      " EPOCH 1/2 step:    20 Batch loss: nan Time avg: 0.43458 sec\n",
      " EPOCH 1/2 step:    40 Batch loss: nan Time avg: 0.14879 sec\n",
      " EPOCH 1/2 step:    60 Batch loss: nan Time avg: 0.15018 sec\n",
      " EPOCH 1/2 step:    80 Batch loss: nan Time avg: 0.15356 sec\n",
      " EPOCH 1/2 step:   100 Batch loss: nan Time avg: 0.15050 sec\n",
      " EPOCH 1/2 step:   120 Batch loss: nan Time avg: 0.15054 sec\n",
      " EPOCH 1/2 step:   140 Batch loss: nan Time avg: 0.14979 sec\n",
      " EPOCH 1/2 step:   160 Batch loss: nan Time avg: 0.16785 sec\n",
      " EPOCH 1/2 step:   180 Batch loss: nan Time avg: 0.14668 sec\n",
      " EPOCH 1/2 step:   200 Batch loss: nan Time avg: 0.15225 sec\n",
      " EPOCH 1/2 step:   220 Batch loss: nan Time avg: 0.14994 sec\n",
      " EPOCH 1/2 step:   240 Batch loss: nan Time avg: 0.15367 sec\n",
      " EPOCH 1/2 step:   260 Batch loss: nan Time avg: 0.14979 sec\n",
      " EPOCH 1/2 step:   280 Batch loss: nan Time avg: 0.15201 sec\n",
      " EPOCH 1/2 step:   300 Batch loss: nan Time avg: 0.15209 sec\n",
      " EPOCH 1/2 step:   320 Batch loss: nan Time avg: 0.15177 sec\n",
      " EPOCH 1/2 step:   340 Batch loss: nan Time avg: 0.15332 sec\n",
      " EPOCH 1/2 step:   360 Batch loss: nan Time avg: 0.15465 sec\n",
      " EPOCH 1/2 step:   380 Batch loss: nan Time avg: 0.15221 sec\n",
      " EPOCH 1/2 step:   400 Batch loss: nan Time avg: 0.15486 sec\n",
      " EPOCH 1/2 step:   420 Batch loss: nan Time avg: 0.15353 sec\n",
      " EPOCH 1/2 step:   440 Batch loss: nan Time avg: 0.14977 sec\n",
      " EPOCH 1/2 step:   460 Batch loss: nan Time avg: 0.14362 sec\n",
      " EPOCH 1/2 step:   480 Batch loss: nan Time avg: 0.15222 sec\n",
      " EPOCH 1/2 step:   500 Batch loss: nan Time avg: 0.14890 sec\n",
      " EPOCH 1/2 step:   520 Batch loss: nan Time avg: 0.14896 sec\n",
      " EPOCH 1/2 step:   540 Batch loss: nan Time avg: 0.15158 sec\n",
      " EPOCH 1/2 step:   560 Batch loss: nan Time avg: 0.15753 sec\n",
      " EPOCH 1/2 step:   580 Batch loss: nan Time avg: 0.15858 sec\n",
      " EPOCH 1/2 step:   600 Batch loss: nan Time avg: 0.15033 sec\n",
      " EPOCH 1/2 step:   620 Batch loss: nan Time avg: 0.16179 sec\n",
      " EPOCH 1/2 step:   640 Batch loss: nan Time avg: 0.15320 sec\n",
      " EPOCH 1/2 step:   660 Batch loss: nan Time avg: 0.14518 sec\n",
      " EPOCH 1/2 step:   680 Batch loss: nan Time avg: 0.15437 sec\n",
      " EPOCH 1/2 step:   700 Batch loss: nan Time avg: 0.14599 sec\n",
      " EPOCH 1/2 step:   720 Batch loss: nan Time avg: 0.14712 sec\n",
      " EPOCH 1/2 step:   740 Batch loss: nan Time avg: 0.15463 sec\n",
      " EPOCH 1/2 step:   760 Batch loss: nan Time avg: 0.15128 sec\n",
      " EPOCH 1/2 step:   780 Batch loss: nan Time avg: 0.15088 sec\n",
      " EPOCH 1/2 step:   800 Batch loss: nan Time avg: 0.15371 sec\n",
      " EPOCH 1/2 step:   820 Batch loss: nan Time avg: 0.15103 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain_segmenter(training_data_path\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtraining_data_path, validation_data_path\u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mvalidation_data_path)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# create and train the net\u001b[39;00m\n\u001b[0;32m     20\u001b[0m net \u001b[38;5;241m=\u001b[39m SegmenterNet(cfg)\n\u001b[1;32m---> 21\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain_segmenter(training_data_path\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtraining_data_path, validation_data_path\u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mvalidation_data_path)\n",
      "File \u001b[1;32m<string>:162\u001b[0m, in \u001b[0;36mtrain_segmenter\u001b[1;34m(self, training_data_path, validation_data_path)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "from config import *\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "cfg = lidar_config()\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "#print(\"Available GPUs after deactivation:\", tf.config.list_physical_devices('GPU'))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "\n",
    "# import the network model after selecting the gpu\n",
    "from segmenter import SegmenterNet\n",
    "\n",
    "def main():\n",
    "\n",
    "    pprint.pprint(cfg)\n",
    "    # create and train the net\n",
    "    net = SegmenterNet(cfg)\n",
    "    net.train_segmenter(training_data_path=cfg.training_data_path, validation_data_path= cfg.validation_data_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9f934-7670-4056-9135-724ec7c75dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb69f34-fa61-4100-bab6-591981191d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
